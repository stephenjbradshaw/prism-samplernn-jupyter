{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aacf539",
   "metadata": {},
   "source": [
    "# PRiSM SampleRNN (Jupyter Notebook)\n",
    "\n",
    "This is a version of RNCM PRiSM's [PRiSM SampleRNN Google Colab notebook](https://colab.research.google.com/gist/relativeflux/10573e9e1b10b1ff45e3a00099259741/prism-samplernn.ipynb#scrollTo=II4WuZilwzWB), adapted for use on GPU-enabled instances in [Amazon SageMaker Studio](https://aws.amazon.com/sagemaker/studio/).\n",
    "\n",
    "[PRiSM SampleRNN](https://www.rncm.ac.uk/research/research-centres-rncm/prism/prism-collaborations/prism-samplernn/) is an AI-assisted composition tool that \"learns\" from audio input to generate new audio output. It is open-source software authored by Dr Christopher Melen, [RNCM PRiSM](https://www.rncm.ac.uk/research/research-centres-rncm/prism/).\n",
    "\n",
    "The environment that this notebook is running is individual to you â€“ you can upload audio, train the model and generate audio without affecting other users of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac697a",
   "metadata": {},
   "source": [
    "## Step 1: Upload input audio\n",
    "N.b. If you would like to use some example audio ([listen](https://drive.google.com/file/d/1BsD9dtglxCzACmDTHGX7pUa5cgdSG-Yh/view?usp=sharing)) instead of uploading your own, skip to \"Prepare the dataset\".\n",
    "1. Identify a suitable input file. This should be a mono `.wav` file. For testing and experimentation, a short file (a few minutes long) is recommended.\n",
    "\n",
    "2. Rename this file to `input.wav`\n",
    "\n",
    "3. Make sure the file browser is open by clicking the \"folder\" icon in the left-hand toolbar\n",
    "\n",
    "4. Open the file picker by clicking the \"up arrow\" icon above the file browser\n",
    "\n",
    "5. Select your file and click \"open\"\n",
    "\n",
    "6. When asked if you want to overwrite, select \"overwrite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b8c98",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset\n",
    "Run the code below, which splits the audio into chunks.\n",
    "1. Click on the code below\n",
    "\n",
    "2. Click the \"play\" icon in the top toolbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bbc88",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!python chunk_audio.py --input_file ../input.wav --output_dir ./chunks/ --chunk_length 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a56b0",
   "metadata": {},
   "source": [
    "## Step 3: Train the model\n",
    "Run the code below, which trains the machine learning model on your input audio using some default parameters.\n",
    "\n",
    "Changing the parameters has a significant effect on the final output. The possible parameters are documented [here](./parameters.md).\n",
    "1. Click on the code below\n",
    "\n",
    "2. Click the \"play\" icon in the top toolbar\n",
    "\n",
    "As the model is trained, it will generate \"checkpoints\", which you will use for generating audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d886395",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "  --data_dir ./chunks \\\n",
    "  --num_epochs 10 \\\n",
    "  --batch_size 21 \\\n",
    "  --max_checkpoints 2 \\\n",
    "  --checkpoint_every 5 \\\n",
    "  --output_file_dur 5 \\\n",
    "  --sample_rate 11025 \\\n",
    "  --resume True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01fb38",
   "metadata": {},
   "source": [
    "## Step 4: Generate audio\n",
    "Modify and run the code below, which generates audio based on the model you just trained.\n",
    "\n",
    "Changing the parameters has a significant effect on the final output. The possible parameters are documented [here](./parameters.md).\n",
    "\n",
    "1. In the file browser on the left, navigate to `prismsamplernn/logdir/default/<dateAndTime>` (double click on folders to open them)\n",
    "\n",
    "2. Once you are in a `<dateAndTime>` folder (e.g. `23.02.2022.06.40`) you should see some checkpoint files (e.g. `model.ckpt-5`, `model.ckpt-10` etc.)\n",
    "\n",
    "3. In the code below, replace `<insertFolderNameHere>` with the name of the checkpoints folder you are in e.g. `23.02.2022.06.40`\n",
    "\n",
    "4. Replace `<insertCheckPointNumberHere>` with the name of the most recent checkpoint, e.g. `10`.\n",
    "\n",
    "5. The final path to the checkpoint should look something like: `./logdir/default/23.02.2022.06.40/model.ckpt-10`\n",
    "\n",
    "5. Click the \"Play\" icon in the top toolbar to run the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c315abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate.py \\\n",
    "  --output_path ./generated/default/output.wav \\\n",
    "  --checkpoint_path ./logdir/default/<insertFolderNameHere>/model.ckpt-<insertCheckPointNumberHere> \\\n",
    "  --dur 10 \\\n",
    "  --sample_rate 11025 \\\n",
    "  --temperature 0.9 \\\n",
    "  --config_file ./default.config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba6565",
   "metadata": {},
   "source": [
    "## Step 5: Download your generated audio\n",
    "\n",
    "1. Generated audio is stored at `prismsamplernn/generated/default`. Navigate to this location using the file browser. (To go \"up\" a level, click on folder names in the bar above the column headers.)\n",
    "\n",
    "2. Once in the correct folder, right click on `output.wav` and click the download button in the menu that appears.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "lcc_arn": "arn:aws:sagemaker:eu-west-2:812387122308:studio-lifecycle-config/on-kernel-start-22-03-13-09-41"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
